{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30152d21-251d-4125-b4c0-74e07778110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: abstention in c:\\users\\q24tian\\appdata\\roaming\\python\\python312\\site-packages (0.1.3.1)\n",
      "Requirement already satisfied: numpy>=1.9 in c:\\users\\q24tian\\appdata\\roaming\\python\\python312\\site-packages (from abstention) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\q24tian\\appdata\\roaming\\python\\python312\\site-packages (from abstention) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\q24tian\\appdata\\roaming\\python\\python312\\site-packages (from abstention) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\q24tian\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.20.0->abstention) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\q24tian\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.20.0->abstention) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Program Files\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install abstention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106cbac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabPFN Accuracy: 0.714\n",
      "Unadapted Test Accuracy: 0.707\n",
      "Adapted Test Accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from abstention.calibration import TempScaling\n",
    "from abstention.label_shift import EMImbalanceAdapter\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "def read_labels(file_handle):\n",
    "    \"\"\"Reads labels from a file handle and returns a one-hot encoded NumPy array.\"\"\"\n",
    "    labels = []\n",
    "    for line in file_handle:\n",
    "        label = int(line.rstrip())\n",
    "        one_hot = np.zeros(10)  # Assuming 10 classes\n",
    "        one_hot[label] = 1\n",
    "        labels.append(one_hot)\n",
    "    return np.array(labels)\n",
    "\n",
    "def read_predictions(file_handle):\n",
    "    \"\"\"Reads predictions from a file handle and returns a NumPy array.\"\"\"\n",
    "    predictions = []\n",
    "    for line in file_handle:\n",
    "        decoded_line = line.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
    "        numeric_predictions = [float(x) for x in decoded_line]\n",
    "        predictions.append(numeric_predictions)\n",
    "    return np.array(predictions)\n",
    "\n",
    "def sample_data(X, y, sample_size):\n",
    "    \"\"\"Randomly samples a subset of X and y, maintaining correspondence.\n",
    "\n",
    "    Args:\n",
    "        X: Input features.\n",
    "        y: Target labels.\n",
    "        sample_size: Number of samples to take.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the sampled X and y.\n",
    "    \"\"\"\n",
    "    assert len(X) == len(y), \"X and y must have the same length\"\n",
    "    indices = np.random.choice(len(X), size=sample_size, replace=False)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# Load data\n",
    "# From paper \"Maximum Likelihood With Bias-Corrected Calibration is Hard-To-Beat at Label Shift Adaptation\"\n",
    "with gzip.open(\"demo_valid_labels.txt.gz\", \"rb\") as f:\n",
    "    valid_labels = read_labels(f)\n",
    "with gzip.open(\"demo_valid_preds.txt.gz\", \"rb\") as f:\n",
    "    valid_preds = read_predictions(f)\n",
    "with gzip.open(\"demo_shifted_test_preds.txt.gz\", \"rb\") as f:\n",
    "    shifted_test_preds = read_predictions(f)\n",
    "with gzip.open(\"demo_shifted_test_labels.txt.gz\", \"rb\") as f:\n",
    "    shifted_test_labels = read_labels(f)\n",
    "\n",
    "y_train = valid_labels\n",
    "X_train = valid_preds\n",
    "X_test = shifted_test_preds\n",
    "y_test = shifted_test_labels\n",
    "\n",
    "# Sample data\n",
    "SAMPLE_SIZE = 500  # Use a constant\n",
    "X_train_sampled, y_train_sampled = sample_data(X_train, y_train, SAMPLE_SIZE)\n",
    "\n",
    "# BCTS Method\n",
    "bcts_calibrator_factory = TempScaling(verbose=False, bias_positions='all')\n",
    "imbalance_adapter = EMImbalanceAdapter(calibrator_factory=bcts_calibrator_factory)\n",
    "\n",
    "imbalance_adapter_func = imbalance_adapter(\n",
    "    valid_labels=y_train_sampled,\n",
    "    tofit_initial_posterior_probs=X_test,\n",
    "    valid_posterior_probs=X_train_sampled\n",
    ")\n",
    "\n",
    "adapted_shifted_test_preds = imbalance_adapter_func(X_test)\n",
    "\n",
    "# TabPFN Method\n",
    "y_train_sampled_tabpfn = np.argmax(y_train_sampled, axis=1)\n",
    "y_test_tabpfn = np.argmax(y_test, axis=1)\n",
    "\n",
    "tabpfn_model = TabPFNClassifier()\n",
    "tabpfn_model.fit(X_train_sampled, y_train_sampled_tabpfn)\n",
    "\n",
    "tabpfn_predictions = tabpfn_model.predict(X_test)\n",
    "print(\"TabPFN Accuracy:\", accuracy_score(y_test_tabpfn, tabpfn_predictions))\n",
    "\n",
    "# No adjustment accuracy\n",
    "unadapted_test_accuracy = np.mean(np.argmax(y_test, axis=-1) == np.argmax(X_test, axis=-1))\n",
    "print(\"Unadapted Test Accuracy:\", unadapted_test_accuracy)\n",
    "\n",
    "# Adapted test accuracy (BCTS)\n",
    "adapted_test_accuracy = np.mean(np.argmax(y_test, axis=-1) == np.argmax(adapted_shifted_test_preds, axis=-1))\n",
    "print(\"Adapted Test Accuracy:\", adapted_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9907838e-7adb-46c0-a2f3-d5d0c0d69bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "from abstention.calibration import TempScaling\n",
    "from abstention.label_shift import EMImbalanceAdapter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def gaussian_mixture(n_samples=1000, proportion=0.5, mean1=[0, 0], cov1=[[1, 0.5], [0.5, 1]],\n",
    "                     mean2=[1, 1], cov2=[[1, -0.3], [-0.3, 1]]):\n",
    "    \"\"\"\n",
    "    Generates a mixture of two Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: Total number of samples.\n",
    "    - proportion: Proportion of samples from the first Gaussian (between 0 and 1).\n",
    "    - mean1, cov1: Mean and covariance of the first Gaussian.\n",
    "    - mean2, cov2: Mean and covariance of the second Gaussian.\n",
    "    \n",
    "    Returns:\n",
    "    - X: (n_samples, d) array of generated data points.\n",
    "    - y: (n_samples,) array of labels (0 for first Gaussian, 1 for second Gaussian).\n",
    "    \"\"\"\n",
    "    n1 = int(n_samples * proportion)\n",
    "    n2 = n_samples - n1\n",
    "    \n",
    "    X1 = np.random.multivariate_normal(mean1, cov1, n1)\n",
    "    X2 = np.random.multivariate_normal(mean2, cov2, n2)\n",
    "    \n",
    "    y1 = np.zeros(n1)\n",
    "    y2 = np.ones(n2)\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    X = np.vstack((X1, X2))\n",
    "    y = np.hstack((y1, y2))\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556a8431-4981-4146-a63d-9b3d92032333",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = gaussian_mixture(n_samples=800, proportion=0.3)\n",
    "X_val, y_val = gaussian_mixture(n_samples=800, proportion=0.3)\n",
    "X_test, y_test = gaussian_mixture(n_samples=800, proportion=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae82b774-6d8c-473d-8450-b8481073aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\q24tian\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabPFN Accuracy: 0.6625\n"
     ]
    }
   ],
   "source": [
    "tabpfn_model = TabPFNClassifier()\n",
    "tabpfn_model.fit(X_train, y_train)\n",
    "tabpfn_predictions = tabpfn_model.predict(X_test)\n",
    "print(\"TabPFN Accuracy:\", accuracy_score(y_test, tabpfn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0cb310c-ffa7-4cf2-9db6-12ca21221cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.67375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.57      0.71       560\n",
      "         1.0       0.48      0.93      0.63       240\n",
      "\n",
      "    accuracy                           0.67       800\n",
      "   macro avg       0.71      0.75      0.67       800\n",
      "weighted avg       0.81      0.67      0.68       800\n",
      "\n",
      "Validation Accuracy: 0.8175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.59      0.66       240\n",
      "         1.0       0.84      0.92      0.88       560\n",
      "\n",
      "    accuracy                           0.82       800\n",
      "   macro avg       0.79      0.75      0.77       800\n",
      "weighted avg       0.81      0.82      0.81       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = lr_classifier.predict(X_test)\n",
    "accuracy_val = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "y_pred_val = lr_classifier.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78328160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapted Test Accuracy: 0.745\n"
     ]
    }
   ],
   "source": [
    "# BCTS Method\n",
    "bcts_calibrator_factory = TempScaling(verbose=False, bias_positions='all')\n",
    "imbalance_adapter = EMImbalanceAdapter(calibrator_factory=bcts_calibrator_factory)\n",
    "\n",
    "val_prob = lr_classifier.predict_proba(X_val)\n",
    "test_prob = lr_classifier.predict_proba(X_test)\n",
    "\n",
    "imbalance_adapter_func = imbalance_adapter(\n",
    "    valid_labels=y_val,\n",
    "    tofit_initial_posterior_probs=test_prob,\n",
    "    valid_posterior_probs=val_prob\n",
    ")\n",
    "\n",
    "adapted_shifted_test_preds = imbalance_adapter_func(test_prob)\n",
    "# Adapted test accuracy (BCTS)\n",
    "adapted_test_accuracy = np.mean(y_test == np.argmax(adapted_shifted_test_preds, axis=-1))\n",
    "print(\"Adapted Test Accuracy:\", adapted_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
